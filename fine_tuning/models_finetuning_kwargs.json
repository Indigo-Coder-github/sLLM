{
    "sota_1b_model_kwargs": {
        "Qwen/Qwen3-1.7B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-3,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "Qwen/Qwen2.5-1.5B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "google/gemma-3-1b-it": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "meta-llama/Llama-3.2-1B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "LGAI-EXAONE/EXAONE-Deep-2.4B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        }
    },
    "sota_3b_model_model_kwargs": {
        "Qwen/Qwen3-4B":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "Qwen/Qwen2.5-3B-Instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-3B":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "google/gemma-3-4b-it":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "meta-llama/Llama-3.2-3B-Instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "microsoft/Phi-4-mini-instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "microsoft/Phi-4-mini-reasoning":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        }
    },
    "sota_70b_quantized_model_kwargs": {
        "meta-llama/Llama-3.3-70B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 16,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.1
        },
        "ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.1
        }
    },
    "medical_model_kwargs": {
        "google/medgemma-27b-text-it": {
            "per_device_train_batch_size": 4,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 1024,
            "learning_rate": 2e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.1
        }
    }
}