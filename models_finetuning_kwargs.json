{
    "sota_1b_model_kwargs": {
        "Qwen/Qwen3-1.7B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "Qwen/Qwen2.5-1.5B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "google/gemma-3-1b-it": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "meta-llama/Llama-3.2-1B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "LGAI-EXAONE/EXAONE-Deep-2.4B": {
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        }
    },
    "sota_3b_model_id_list": {
        "Qwen/Qwen3-4B":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "Qwen/Qwen2.5-3B-Instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-3B":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "google/gemma-3-4b-it":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "meta-llama/Llama-3.2-3B-Instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "microsoft/Phi-4-mini-instruct":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        },
        "microsoft/Phi-4-mini-reasoning":{
            "per_device_train_batch_size": 1,
            "per_device_eval_batch_size": 1,
            "gradient_accumulation_steps": 256,
            "learning_rate": 1e-4,
            "num_train_epochs": 3,
            "save_strategy": "best",
            "eval_steps": 0.2
        }
    }
}